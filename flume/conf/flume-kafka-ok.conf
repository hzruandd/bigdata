# Name the components on this agent
agent1.sources = r1
agent1.sinks = k1
agent1.channels = c1

# Describe/configure the source
agent1.sources.r1.type = netcat
agent1.sources.r1.bind = localhost
agent1.sources.r1.port = 44444

# Describe/configure the source
#agent1.sources.r1.type = spooldir
#agent1.sources.r1.spoolDir=/home/afa4j/afa4j/log/app/gid2/bigdata/20161028/createlog1
agent1.sources.r1.type = exec
agent1.sources.r1.command = tail -F /home/rdd/bigfile.log
#agent1.sources.r1.inputCharset = utf-8
agent1.sources.r1.fileHeader = true
agent1.sources.r1.deletePolicy = immediate

#agent1.sources.tailsource-1.type = exec
#agent1.sources.tailsource-1.shell = /bin/bash -c
#agent1.sources.tailsource-1.command = for i in /path/*.txt; do cat $i; done
#
#

# Describe the sink
agent1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.k1.topic = kafka2spark
agent1.sinks.k1.brokerList = 10.8.6.153:9092
agent1.sinks.k1.requiredAcks = 1
agent1.sinks.k1.batchSize = 20

# Use a channel which buffers events in memory
agent1.channels.c1.type = memory
agent1.channels.c1.capacity = 1000
agent1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
agent1.sources.r1.channels = c1
agent1.sinks.k1.channel = c1
